{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51339a6e-fd93-4b80-8c57-dfeb865b3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab95780f-d1d2-42f2-b15f-5e031415fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image preprocessing transform\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  # ResNet standard input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet stats\n",
    "])\n",
    "\n",
    "def load_model(model_path, num_classes):\n",
    "    model = models.resnet34(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Inference function\n",
    "def predict_char(image_path, model, class_names):\n",
    "    \"\"\"\n",
    "    Perform inference on a single image.\n",
    "\n",
    "    Args:\n",
    "    - image_path (str): Path to the input image.\n",
    "    - model (torch.nn.Module): Trained PyTorch model.\n",
    "    - class_names (list of str): List of class names.\n",
    "\n",
    "    Returns:\n",
    "    - str: Predicted class name.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = preprocess(image)\n",
    "    # print(type(input_tensor))\n",
    "    plt.imshow(input_tensor.view(-1, 224).cpu().numpy())\n",
    "    plt.show()\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Create a mini-batch as expected by the model\n",
    "\n",
    "    # Move the input to the same device as the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_batch = input_batch.to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "        _, predicted_idx = torch.max(output, 1)\n",
    "\n",
    "    # Get the class label\n",
    "    predicted_class = class_names[predicted_idx.item()]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5abd74b-babe-4771-ae8a-09b8ea47bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbdesk/pubg_parser/char_classifier/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hbdesk/pubg_parser/char_classifier/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the model and class names\n",
    "model_path = \"./char_classifier.pth\"\n",
    "class_names = ['-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', \n",
    "               'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', \n",
    "               'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']',\n",
    "               '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "               'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "model = load_model(model_path, num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b38d6e-ed4b-4dd2-af3e-de996b7b5959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
