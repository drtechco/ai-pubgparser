{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a599d8-2097-45df-9867-fba36f3e96c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbdesk/labelstudio_convert/venv/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import math \n",
    "import albumentations as A\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72bfb5cd-ee4e-4b10-8d12-d091236afe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_STUDIO_KEY=\"eaffb8f4719efb17f9b227ed56fee991c4d06a0a\"\n",
    "LABEL_STUDIO_URL=\"http://192.168.231.52:8080/\"\n",
    "\n",
    "def bgr2_3grey(image: np.ndarray):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_bgr = cv2.merge([gray_image, gray_image, gray_image])\n",
    "    return gray_bgr\n",
    "    \n",
    "def get_img_from_studio(image_path, save_path=\"./captioned_images\"):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    download_url = f\"{LABEL_STUDIO_URL}{image_path}\"\n",
    "    headers = {\n",
    "        'Authorization': f'Token {LABEL_STUDIO_KEY}'\n",
    "    }\n",
    "    response = requests.get(download_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        filename = os.path.basename(image_path)\n",
    "        save_path = os.path.join(save_path, filename)\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "            return save_path\n",
    "        print(f\"Image successfully downloaded as {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def export_label_txt(label_dict_list: list, txt_type: str):\n",
    "    \"\"\"\n",
    "    takes a list of annotation pairs that looks like \n",
    "    `Image_path`\\t`Label`\\n\n",
    "    \"\"\"\n",
    "    if txt_type.lower() == \"train\":\n",
    "        with open(\"rec_gt_train.txt\", \"w\", encoding='utf-8') as train_txt:\n",
    "            for _a in label_dict_list:\n",
    "                for key, value in _a.items():\n",
    "                    train_txt.write(f\"{str(key)}\\t{str(value)}\\n\")\n",
    "    elif txt_type.lower() == \"eval\":\n",
    "        with open(\"rec_gt_eval.txt\", \"w\", encoding='utf-8') as eval_txt:\n",
    "            for _a in label_dict_list:\n",
    "                for key, value in _a.items():\n",
    "                    eval_txt.write(f\"{key}\\t{str(value)}\\n\")\n",
    "    else:\n",
    "        print(f\"invalid export type {txt_type}!\")\n",
    "\n",
    "def separate_train_eval(all_anno: list,train_sep: float = 0.8):\n",
    "    _all_anno = all_anno.copy() # copy so we dont fuck up the original shit homie\n",
    "    _train_num = math.floor(len(_all_anno) * train_sep) \n",
    "    train_set = []\n",
    "    _sel_count = _train_num\n",
    "    for _ in range(_train_num):\n",
    "        random_index = random.randint(0, (_sel_count - 1))\n",
    "        _sel_count -= 1\n",
    "        _sel  = _all_anno[random_index]\n",
    "        train_set.append(_sel)\n",
    "        # remove from the copied array and use remaining as eval, avoid copying twice\n",
    "        _all_anno.pop(_all_anno.index(_sel)) \n",
    "    return train_set, _all_anno \n",
    "\n",
    "def convert2gray(file_path: str):\n",
    "    for file in os.listdir(file_path):\n",
    "        img_path = os.path.join(file_path, file)\n",
    "        img = bgr2_3grey(cv2.imread(img_path))\n",
    "        cv2.imwrite(img_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f8cc02-b376-4106-9469-20069954bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_query_string(img_path: str, img_caption: str):\n",
    "    return {\n",
    "              \"query\": \"<image>\",\n",
    "              \"response\": f\"{img_caption}\",\n",
    "              \"images\": [img_path]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d82fc40-798e-42e3-b8e0-d1d4eacae7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [{'completed_by': 2,\n",
      "                  'created_at': '2024-11-01T07:06:27.712531Z',\n",
      "                  'draft_created_at': None,\n",
      "                  'ground_truth': False,\n",
      "                  'id': 2088,\n",
      "                  'import_id': None,\n",
      "                  'last_action': None,\n",
      "                  'last_created_by': None,\n",
      "                  'lead_time': 17.095,\n",
      "                  'parent_annotation': None,\n",
      "                  'parent_prediction': None,\n",
      "                  'prediction': {},\n",
      "                  'project': 6,\n",
      "                  'result': [{'from_name': 'caption',\n",
      "                              'id': '9U2QMRVai8',\n",
      "                              'origin': 'manual',\n",
      "                              'to_name': 'image',\n",
      "                              'type': 'textarea',\n",
      "                              'value': {'text': ['PeRo_longdd']}}],\n",
      "                  'result_count': 0,\n",
      "                  'task': 2852,\n",
      "                  'unique_id': '3d9f9cc4-bd8e-4030-887c-dcbfa7680d11',\n",
      "                  'updated_at': '2024-11-01T07:06:27.712546Z',\n",
      "                  'updated_by': 2,\n",
      "                  'was_cancelled': False}],\n",
      " 'cancelled_annotations': 0,\n",
      " 'comment_authors': [],\n",
      " 'comment_count': 0,\n",
      " 'created_at': '2024-11-01T07:04:56.627862Z',\n",
      " 'data': {'captioning': '/data/upload/6/c10716c3-b4686210d10a4c9ba87e7e21ca151f9b.png'},\n",
      " 'drafts': [],\n",
      " 'file_upload': 'c10716c3-b4686210d10a4c9ba87e7e21ca151f9b.png',\n",
      " 'id': 2852,\n",
      " 'inner_id': 1,\n",
      " 'last_comment_updated_at': None,\n",
      " 'meta': {},\n",
      " 'predictions': [],\n",
      " 'project': 6,\n",
      " 'total_annotations': 1,\n",
      " 'total_predictions': 0,\n",
      " 'unresolved_comment_count': 0,\n",
      " 'updated_at': '2024-11-01T07:06:27.783971Z',\n",
      " 'updated_by': 2}\n"
     ]
    }
   ],
   "source": [
    "with open(\"./2.7_BOLD.json\", \"r\") as load_labelled:\n",
    "    data = json.loads(load_labelled.read())\n",
    "pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "535e1f38-d5bd-4ade-bdf3-b26f734c8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_query_list = []\n",
    "for annotation in data:\n",
    "    try:\n",
    "        text_string = annotation[\"annotations\"][0][\"result\"][0][\"value\"][\"text\"][0]\n",
    "        file_name = annotation[\"data\"][\"captioning\"]\n",
    "        image_name = get_img_from_studio(file_name, \"/home/hbdesk/labelstudio_convert/captioned_images\")\n",
    "        if image_name is not None:\n",
    "            query_ = new_query_string(image_name, text_string)\n",
    "            final_query_list.append(query_)\n",
    "    except Exception as _:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d48c336-312f-4595-8610-da37e7956ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GOT2_data.jsonl\", \"w\") as writejson:\n",
    "    for item in final_query_list:\n",
    "        writejson.write(json.dumps(item) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
